knitr::opts_chunk$set(echo = TRUE)
#Ejecute las siguientes tres líneas de código para crear las variables
x = c(1, 2, 4, 7, 9, 0)
y = 4
z = c(0.5, 2, 3, 5, 1, 0)
# Escriba en el siguiente espacio la operación suma entre "x" y "y", y asígnelo a resultado_suma (1 línea de código)
resultado_suma <-
# Escriba en el siguiente espacio la operación multiplicación entre "x" y "z", y asígnelo a resultado_multiplicacion (1 línea de código)
resultado_multiplicacion <-
# Escriba en el siguiente espacio la operación multiplicación negativa a "z", y asígnelo a resultado_negativo (1 línea de código)
resultado_negativo <-
# Escriba en el siguiente espacio la operación de raíz cuadrada "y", y asígnelo a resultado_raiz (1 línea de código)
resultado_raiz <-
# Escriba en el siguiente espacio la operación lógica de igualdad entre "x" y "z", y asígnelo a resultado_igualdad (1 línea de código)
resultado_igualdad <-
# Escriba en el siguiente espacio la operación lógica de diferencia entre "x" y "y", y asígnelo a resultado_igualdad (1 línea de código)
resultado_diferencia <-
# --------------------------- #
# Ahora ejecute las siguientes líneas de código que le permitirán observar los resultados de sus operaciones.
print("Resultado Suma")
resultado_suma
print("Resultado multiplicación")
resultado_multiplicacion
print("Resultado negativo")
resultado_negativo
print("Resultado raíz cuadrada")
resultado_raiz
print("Resultado de operación lógica: igualdad")
resultado_igualdad
print("Resultado de operación lógica: diferencia")
resultado_diferencia
x = c(1, 2, 4, 7, 9, 0)
y = 4
z = c(0.5, 2, 3, 5, 1, 0)
x = c(1, 2, 4, 7, 9, 0)
y = 4
z = c(0.5, 2, 3, 5, 1, 0)
#Ejecute las siguientes tres líneas de código para crear las variables
x = c(1, 2, 4, 7, 9, 0)
y = 4
z = c(0.5, 2, 3, 5, 1, 0)
# Escriba en el siguiente espacio la operación suma entre "x" y "y", y asígnelo a resultado_suma (1 línea de código)
resultado_suma <- x+y
# Escriba en el siguiente espacio la operación multiplicación entre "x" y "z", y asígnelo a resultado_multiplicacion (1 línea de código)
resultado_multiplicacion <- x*z
# Escriba en el siguiente espacio la operación multiplicación negativa a "z", y asígnelo a resultado_negativo (1 línea de código)
resultado_negativo <- -z
# Escriba en el siguiente espacio la operación de raíz cuadrada "y", y asígnelo a resultado_raiz (1 línea de código)
resultado_raiz <- sqrt(y)
# Escriba en el siguiente espacio la operación lógica de igualdad entre "x" y "z", y asígnelo a resultado_igualdad (1 línea de código)
resultado_igualdad <- x==z
# Escriba en el siguiente espacio la operación lógica de diferencia entre "x" y "y", y asígnelo a resultado_igualdad (1 línea de código)
resultado_diferencia <- x!=y
# --------------------------- #
# Ahora ejecute las siguientes líneas de código que le permitirán observar los resultados de sus operaciones.
print("Resultado Suma")
resultado_suma
print("Resultado multiplicación")
resultado_multiplicacion
print("Resultado negativo")
resultado_negativo
print("Resultado raíz cuadrada")
resultado_raiz
print("Resultado de operación lógica: igualdad")
resultado_igualdad
print("Resultado de operación lógica: diferencia")
resultado_diferencia
knitr::opts_chunk$set(echo = TRUE)
#install.packages("tidyverse")
install.packages("nycflights13")
#install.packages("tidyverse")
#install.packages("nycflights13")
#install.packages("xts")
install.packages("PerformanceAnalytics")
anova(reg2,reg1)
data<-read.csv(file.choose())
head(data,3)
D<-year>=1991
data$D<-as.numeric(D)
data[29:36,]
reg1<-lm(log_PIB_Col~D+log_PIB_USA+D*log_PIB_USA,data = data)
reg2<-lm(log_PIB_Col~log_PIB_USA,data=data)
anova(reg2,reg1)
data<-read.csv(file.choose())
attach(data)
D<-year>=1991
data$D<-as.numeric(D)
data[29:36,]
reg1<-lm(log_PIB_Col~D+log_PIB_USA+D*log_PIB_USA,data = data)
reg2<-lm(log_PIB_Col~log_PIB_USA,data=data)
anova(reg2,reg1)
data <- read_excel(file.choose())
library(readxl)
data <- read_excel(file.choose())
setwd("F:/GitHub/Maestría en Ciencia de Datos/Análisis Cuantitativo")
setwd("F:/GitHub/Maestría en Ciencia de Datos/Análisis Cuantitativo/Archivos")
data<-read.csv("DatosTallerSelAuto.csv", header=TRUE)
formula.modelo <- shares ~ 1 + timedelta + n_tokens_title + num_hrefs + average_token_length +
data_channel_is_entertainment + kw_min_avg + kw_max_avg + kw_avg_avg + self_reference_min_shares +
global_subjectivity + max_negative_polarity
modelo <- lm(formula.modelo, data = data)
summary(modelo)
library(olsrr)
ols_plot_resid_qq(modelo)
ks.test(resid(modelo), "pnorm")
library(lmtest)
bptest(modelo, studentize = TRUE)
attach(data)
bptest(modelo, ~ timedelta + n_tokens_title + num_hrefs + average_token_length +
data_channel_is_entertainment + kw_min_avg + kw_max_avg +
kw_avg_avg + self_reference_min_shares + global_subjectivity +
max_negative_polarity+
I(timedelta^2) + I(n_tokens_title^2) + I(num_hrefs^2) + I(average_token_length^2) + I( data_channel_is_entertainment^2) + I(kw_min_avg^2) + I(kw_max_avg^2) + I(kw_avg_avg^2) + I(self_reference_min_shares^2) + I(global_subjectivity^2) + I(    max_negative_polarity) +
n_tokens_title* timedelta +num_hrefs* timedelta +average_token_length* timedelta + data_channel_is_entertainment* timedelta +kw_min_avg* timedelta +kw_max_avg* timedelta +kw_avg_avg* timedelta +self_reference_min_shares* timedelta +global_subjectivity* timedelta +    max_negative_polarity* timedelta+
timedelta* n_tokens_title + num_hrefs* n_tokens_title +average_token_length* n_tokens_title + data_channel_is_entertainment* n_tokens_title +kw_min_avg* n_tokens_title +kw_max_avg* n_tokens_title +kw_avg_avg* n_tokens_title +self_reference_min_shares* n_tokens_title +global_subjectivity* n_tokens_title +    max_negative_polarity* n_tokens_title +
timedelta* num_hrefs + n_tokens_title* num_hrefs+average_token_length* num_hrefs+ data_channel_is_entertainment* num_hrefs+kw_min_avg* num_hrefs+kw_max_avg* num_hrefs+kw_avg_avg* num_hrefs+self_reference_min_shares* num_hrefs+global_subjectivity* num_hrefs+    max_negative_polarity* n_tokens_title +
timedelta* average_token_length+n_tokens_title* average_token_length+average_token_length* average_token_length+ data_channel_is_entertainment* average_token_length+kw_min_avg* average_token_length+kw_max_avg* average_token_length+kw_avg_avg* average_token_length+self_reference_min_shares* average_token_length+global_subjectivity* average_token_length+    max_negative_polarity* n_tokens_title +
timedelta* data_channel_is_entertainment+n_tokens_title* data_channel_is_entertainment+kw_min_avg* data_channel_is_entertainment+kw_max_avg* data_channel_is_entertainment+kw_avg_avg* data_channel_is_entertainment+self_reference_min_shares* data_channel_is_entertainment+global_subjectivity* data_channel_is_entertainment+    max_negative_polarity* n_tokens_title +
timedelta* self_reference_min_shares+n_tokens_title* self_reference_min_shares+kw_min_avg* self_reference_min_shares+kw_max_avg* self_reference_min_shares+kw_avg_avg* self_reference_min_shares+self_reference_min_shares* self_reference_min_shares+global_subjectivity* self_reference_min_shares+    max_negative_polarity* n_tokens_title
)
dettach(data)
detach(data)
library(sandwich)
coeftest(modelo, vcov = (vcovHC(modelo)))
formula.modelo2 <- shares ~ 1 + timedelta + n_tokens_title + num_hrefs + average_token_length + data_channel_is_entertainment + kw_min_avg + kw_max_avg + kw_avg_avg + self_reference_min_shares + global_subjectivity
modelo2 <- lm(formula.modelo2, data = data)
coeftest(modelo2, vcov = (vcovHC(modelo2)))
install.packages("lm.beta")
library(lm.beta)
library(lm.beta)
modelo2.s <- lm.beta(modelo2)
# coeficientes estandarizados
coeftest(modelo2.s, vcov = (vcovHC(modelo2)))
modelo2.s$standardized.coefficients
summary(modelo2.s)
coef(modelo2.s)
coef(modelo2.s)[which.max(coef(modelo2.s))]
coef(modelo2.s)[which.max(abs(coef(modelo2.s)))]
coef.est <- matrix(0,10,2)
var.names  <- c(names(modelo2.s$standardized.coefficients)[-1])
coef.est <- matrix(modelo2.s$standardized.coefficients[-1])
coef.estand <- as.data.frame(var.names)
coef.estand$coef.est <- coef.est
library(ggplot2)
p <- ggplot(data=coef.estand, aes(x=var.names, y=coef.est)) +
geom_bar(stat="identity", fill="steelblue") +
ggtitle("Coeficientes estandarizados")
p + coord_flip()
escenario = data.frame(mean(data$timedelta),  mean(data$n_tokens_title) ,
mean(data$num_hrefs), mean(data$average_token_length),
mean(data$data_channel_is_entertainment), mean(data$kw_min_avg),
mean(data$kw_max_avg), mean(data$kw_avg_avg),
mean(data$self_reference_min_shares), mean(data$global_subjectivity))
names(escenario) <- c("timedelta", "n_tokens_title", "num_hrefs", "average_token_length",
"data_channel_is_entertainment", "kw_min_avg", "kw_max_avg",
"kw_avg_avg", "self_reference_min_shares", "global_subjectivity")
predict(modelo2, newdata = escenario,  level = 0.95, interval="confidence")
predict(modelo2, newdata = escenario,  level = 0.99, interval="confidence")
library(jtools)
plot_summs(modelo2)
plot_summs(modelo2, robust = "HC3")
plot_summs(modelo2, robust = "HC3", scale = TRUE, transform.response = TRUE)
plot_summs(modelo2, robust = "HC3", scale = TRUE, transform.response = TRUE, inner_ci_level = .9)
plot_summs(modelo2, robust = "HC3", inner_ci_level = .9, plot.distributions = TRUE, rescale.distributions = TRUE)
plot_summs(modelo, modelo2, robust = "HC3", inner_ci_level = .9)
plot_summs(modelo, modelo2, scale = TRUE, transform.response = TRUE, robust = "HC3", inner_ci_level = .9)
plot_summs(modelo, modelo2, robust = "HC3", plot.distributions = TRUE, rescale.distributions = TRUE)
plot_summs(modelo2, modelo2, modelo2, scale = TRUE, robust = list(FALSE, "HC0", "HC3"),
model.names = c("OLS", "HC0", "HC3"))
plot_summs(modelo2, robust = "HC3", plot.distributions = TRUE, rescale.distributions = TRUE, omit.coefs = "global_subjectivity")
plot_summs(modelo2, robust = "HC3", plot.distributions = TRUE, rescale.distributions = TRUE, omit.coefs = c("global_subjectivity", "(Intercept)"))
